{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import os, re\n",
    "import Levenshtein\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Users/prabh/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the file paths from the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_files_in_folder(folder_path):\n",
    "    file_paths = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    \n",
    "    return file_paths\n",
    "\n",
    "folder_path = \"assets/\"\n",
    "file_paths = list_files_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match if the face is visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def is_face_visible(image_path):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    img = cv2.imread(image_path)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    if len(faces) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "for file in file_paths:\n",
    "    print(is_face_visible(str(file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match the processed texts with the required list of datas to find the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_parts(target, input_text, threshold = 0.60):\n",
    "    similar_parts = []\n",
    "    words = input_text.split()\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        for j in range(i+1, len(words) + 1):\n",
    "            part = ' '.join(words[i:j])\n",
    "            similarity = 1 - Levenshtein.distance(target, part) / max(len(target), len(part))\n",
    "            if similarity >= threshold:\n",
    "                similar_parts.append((part, similarity))\n",
    "    \n",
    "    similar_parts.sort(key=lambda x: x[1], reverse=True)\n",
    "    if similar_parts:\n",
    "        return similar_parts[0][0]\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMissMatchPercentage(image_path):\n",
    "    processedImages = multyProcessImages(image_path)\n",
    "    left_aligned_list = [\"Date of Birth\", \"Address\", \"Expiration Date\"]\n",
    "    center_aligned_list = [\"Blood Type\", \"Agency Code\", \"Eyes Color\"]\n",
    "    status = computeStatus(processedImages, left_aligned_list, center_aligned_list)\n",
    "    for key in status.keys():\n",
    "        print(key, \":\", status[key])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'Date of Birth': False, 'Address': False, 'Expiration Date': False, 'Blood Type': False, 'Agency Code': False, 'Eyes Color': False}\n",
    "\n",
    "def compare_left_allignment(part,strings,extracts):\n",
    "    if(strings == \"Date of Birth\" or strings == \"Expiration Date\"):\n",
    "        pattern = '^(19|20)\\d\\d/(0[1-9]|1[012])/(0[1-9]|[12][0-9]|3[01])$'\n",
    "        coord_list = []\n",
    "        n_boxes = len(extracts['text'])\n",
    "        for i in range(n_boxes):\n",
    "            if int(extracts['conf'][i]) > 10:\n",
    "                if re.match(pattern, extracts['text'][i]):\n",
    "                    (x, y, w, h) = (extracts['left'][i], extracts['top'][i], extracts['width'][i], extracts['height'][i])\n",
    "                    coord_list.append(x)\n",
    "                if extracts['text'][i] == part.split(' ')[0]:\n",
    "                    (x, y, w, h) = (extracts['left'][i], extracts['top'][i], extracts['width'][i], extracts['height'][i])\n",
    "                    coord_list.append(x)\n",
    "                if len(coord_list) == 2:\n",
    "                    if coord_list[0] - coord_list[1] <= 5:\n",
    "                        return True\n",
    "                    else:\n",
    "                        return False\n",
    "\n",
    "    if(strings == \"Address\"):\n",
    "        return True\n",
    "\n",
    "def compare_center_allignment(part,strings,extracts):\n",
    "    pattern = \" \"\n",
    "    if(strings == \"Blood Type\"):\n",
    "        pattern = '^(A|B|AB|O)[+-]$'\n",
    "    if(strings == \"Agency Code\"):\n",
    "        pattern = r'[A-Z][0-9]{2}'\n",
    "    if(strings == \"Eyes Color\"):\n",
    "        pattern = '^(BLACK|BLUE|GRAY)$'\n",
    "    coordinate = 0\n",
    "    coord_list = []\n",
    "    n_boxes = len(extracts['text'])\n",
    "    for i in range(n_boxes):\n",
    "        if int(extracts['conf'][i]) > 10:\n",
    "            if re.match(pattern, extracts['text'][i]):\n",
    "                (x, y, w, h) = (extracts['left'][i], extracts['top'][i], extracts['width'][i], extracts['height'][i])\n",
    "                coord_list.append(x)\n",
    "                coordinate += x + w/2\n",
    "            if extracts['text'][i] in part.split(' '):\n",
    "                (x, y, w, h) = (extracts['left'][i], extracts['top'][i], extracts['width'][i], extracts['height'][i])\n",
    "                if extracts['text'][i] == part.split(' ')[0]:\n",
    "                    coord_list.append(x)\n",
    "                    coordinate -= (x+w/2)\n",
    "                else:\n",
    "                    coordinate -= w/2\n",
    "            \n",
    "    if abs(coordinate) <= 5 and coord_list[0] - coord_list[1] > 5:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isFaceVisible(gray_image):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    return len(faces)>0\n",
    "\n",
    "def multyProcessImages(image_path):\n",
    "    images = []\n",
    "    image = cv2.imread(image_path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    images.append(gray_image)\n",
    "\n",
    "    gussian_image = cv2.GaussianBlur(src=gray_image,ksize=(3, 3), sigmaX=0,sigmaY=0)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(12, 12))\n",
    "    clached_image = clahe.apply(gray_image)\n",
    "\n",
    "    unsharp_image = cv2.addWeighted(clached_image, 2.0, gray_image, -1.0, 0)\n",
    "\n",
    "    _, thresold_image1 = cv2.threshold(gussian_image, thresh=165, maxval=255, type=cv2.THRESH_TRUNC + cv2.THRESH_OTSU)\n",
    "    images.append(thresold_image1)\n",
    "\n",
    "    _, thresold_image2 = cv2.threshold(gray_image, thresh=165, maxval=255, type=cv2.THRESH_TRUNC + cv2.THRESH_OTSU)\n",
    "    images.append(thresold_image2)\n",
    "\n",
    "    _, thresold_image3 = cv2.threshold(clached_image, thresh=165, maxval=255, type=cv2.THRESH_TRUNC + cv2.THRESH_OTSU)\n",
    "    images.append(thresold_image3)\n",
    "\n",
    "    _, thresold_image4 = cv2.threshold(unsharp_image, thresh=165, maxval=255, type=cv2.THRESH_TRUNC + cv2.THRESH_OTSU)\n",
    "    images.append(thresold_image4)\n",
    "    \n",
    "    return images\n",
    "\n",
    "def fillStatus(image,left_list,centerd_list):\n",
    "    global parameters\n",
    "    extracts = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
    "    extracted_text = pytesseract.image_to_string(image)\n",
    "    for strings in left_list:\n",
    "        part = find_similar_parts(strings,extracted_text)     \n",
    "        if(part != False):\n",
    "            if(compare_left_allignment(part, strings, extracts)):\n",
    "                parameters[strings] = True\n",
    "    \n",
    "    for strings in centerd_list:\n",
    "        part = find_similar_parts(strings,extracted_text)     \n",
    "        if(part != False):\n",
    "            if(compare_center_allignment(part, strings, extracts)):\n",
    "                parameters[strings] = True\n",
    "\n",
    "def computeStatus(procesd_images,left_list,centerd_list):\n",
    "    status = {'msimatch percentage': 0.0, 'face visibility': False, 'matched parameters': [], 'mismatched parameters': []}\n",
    "    global parameters\n",
    "    mmpercentage = 0.0\n",
    "        \n",
    "    face_visibility = isFaceVisible(procesd_images[0])\n",
    "    \n",
    "    if face_visibility:\n",
    "        status['face visibility'] = True\n",
    "    else:\n",
    "        mmpercentage += 33.33\n",
    "\n",
    "    for image in procesd_images:\n",
    "        fillStatus(image,left_list,centerd_list)\n",
    "\n",
    "    for key in parameters:\n",
    "        if parameters[key]:\n",
    "            status['matched parameters'].append(key)\n",
    "        else:\n",
    "            status['mismatched parameters'].append(key)\n",
    "            mmpercentage += 11.11\n",
    "    \n",
    "    status['msimatch percentage'] = mmpercentage\n",
    "            \n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msimatch percentage : 33.33\n",
      "face visibility : True\n",
      "matched parameters : ['Date of Birth', 'Address', 'Expiration Date']\n",
      "mismatched parameters : ['Blood Type', 'Agency Code', 'Eyes Color']\n",
      "\n",
      "None\n",
      "msimatch percentage : 55.55\n",
      "face visibility : False\n",
      "matched parameters : ['Date of Birth', 'Address', 'Expiration Date', 'Eyes Color']\n",
      "mismatched parameters : ['Blood Type', 'Agency Code']\n",
      "\n",
      "None\n",
      "msimatch percentage : 22.22\n",
      "face visibility : True\n",
      "matched parameters : ['Date of Birth', 'Address', 'Expiration Date', 'Eyes Color']\n",
      "mismatched parameters : ['Blood Type', 'Agency Code']\n",
      "\n",
      "None\n",
      "msimatch percentage : 22.22\n",
      "face visibility : True\n",
      "matched parameters : ['Date of Birth', 'Address', 'Expiration Date', 'Eyes Color']\n",
      "mismatched parameters : ['Blood Type', 'Agency Code']\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Unit testing for isFaceVisible function\n",
    "for file in file_paths:\n",
    "    print(findMissMatchPercentage(str(file)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the directory path\n",
    "directory = 'W:/PersonalProject/ID_card_authentication/assets'\n",
    "\n",
    "# Get a list of all image files in the directory\n",
    "image_files = [f for f in os.listdir(directory) if f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.png')]\n",
    "\n",
    "# Sort the list of image files alphabetically\n",
    "image_files.sort()\n",
    "\n",
    "# Rename each image file with a new name\n",
    "for i, image_file in enumerate(image_files):\n",
    "    # Construct the new file name\n",
    "    new_file_name = 'image' + str(i+1) + os.path.splitext(image_file)[1]\n",
    "    \n",
    "    # Construct the full file paths\n",
    "    old_file_path = os.path.join(directory, image_file)\n",
    "    new_file_path = os.path.join(directory, new_file_name)\n",
    "    \n",
    "    # Rename the file\n",
    "    os.rename(old_file_path, new_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
